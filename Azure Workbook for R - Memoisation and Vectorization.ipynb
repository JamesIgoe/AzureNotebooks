{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R: Memoisation and Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full of potential coding improvements, Efficient R Programming: A Practical Guide to Smarter Programming (https://www.goodreads.com/book/show/28646688-efficient-r-programming), the book makes two suggestions that are notable. Vectorization, explained here (http://www.noamross.net/blog/2014/4/16/vectorization-in-r--why.html) and here (http://alyssafrazee.com/2014/01/29/vectorization.html), and memoisation, caching prior results albeit with additional memory use, were relevant and significant. \n",
    "\n",
    "What follows is a demonstration of the speed improvements that might be achieved using these concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code creates a slow function, memoises it, create a vectorized form of the slow function, and then memoises the vectorized form. In sections Pass 1 and Pass 2, you can see the result of the techniques against the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(memoise)\n",
    "\n",
    "monte_carlo = function(N) {\n",
    "    hits = 0\n",
    "    for (i in seq_len(N)) {\n",
    "        u1 = runif(1)\n",
    "        u2 = runif(1)\n",
    "        if (u1 ^ 2 > u2)\n",
    "            hits = hits + 1\n",
    "        }\n",
    "    return(hits / N)\n",
    "}\n",
    "\n",
    "monte_carlo_memo <- memoise(monte_carlo)\n",
    "\n",
    "monte_carlo_vec <- function(N) mean(runif(N) ^ 2 > runif(N))\n",
    "\n",
    "monte_carlo_vec_memo <- memoise(monte_carlo_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pass 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of the first pass shows that vectorization provides a vast improvement over a standard for loop, and that memoise provides little of an improvement over that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n <- 999999\n",
    "plainFor <- system.time(monte_carlo(n))\n",
    "memoised <- system.time(monte_carlo_memo(n))\n",
    "vectorised <- system.time(monte_carlo_vec(n))\n",
    "both <- system.time(monte_carlo_vec_memo(n))\n",
    "\n",
    "result <- cbind(plainFor, memoised, vectorised, both)\n",
    "displayPass1 <- format(result, digits = 2, nsmall = 2)\n",
    "displayPass1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pass 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That said, on a a second pass over the same loops, memoisation is vastly faster, returning values in zero (0) seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plainFor <- system.time(monte_carlo(n))\n",
    "memoised <- system.time(monte_carlo_memo(n))\n",
    "vectorised <- system.time(monte_carlo_vec(n))\n",
    "both <- system.time(monte_carlo_vec_memo(n))\n",
    "\n",
    "result <- cbind(plainFor, memoised, vectorised, both)\n",
    "displayPass2 <- format(result, digits = 2, nsmall = 2)\n",
    "displayPass2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "python",
   "pygments_lexer": "r",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
